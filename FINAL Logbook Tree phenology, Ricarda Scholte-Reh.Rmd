---
title: "Tree phenology analysis with R"
author: "Ricarda Scholte-Reh"
date: "2025-03-04"
homepage: "https://Ricarda-Scholte-Reh.github.io"
output:
  html_document:
    theme: flatly
    toc: true
    toc_float: true
    toc_depth: 2
    number_sections: false
---

This logbook will answer the Exercises of the module "Tree phenology analysis in R". It will start with chapter 3, ends with chapter 35 and will only shortly tell if a chapter is left out (like chapter 17).\

# Chapter 03 Tree dormancy

1.  Put yourself in the place of a breeder who wants to calculate the temperature requirements of a newly released cultivar. Which method will you use to calculate the chilling and forcing periods?\

    -   Because the cultivar is already released there should be official data about the cultivar. Therefore I would use these data to calculate the temperature requirements. As base data I need the long phenological data sets and temperature records. With these I can calculate finally the date of dormancy overcome.\

2.  Which are the advantages (name 2) of the BBCH scale compared with early scales?

    -   Growth stages are easily recognizable under field conditions.

    -   Growth stages are graded in the order of appearance.

3.  Classify the following phenological stages of sweet cherry according to the BBCH scale.

    The pictures are described from left to right. All of the classifications are based on the given pictures and I assume that the image section shown corresponds to the most represented of the tree.

    -   Picture 1: BBCH-stage 03
        -   Main stage: 00: sprouting
        -   Stage 03: end of the bud swelling (leave buds), parts of the buds are light green, the bud scales are spread apart
    -   Picture 2: BBCH-stage 65
        -   Main stage 60: Flowering
        -   Stage 65: Full flowering, at least 50 % of the flowers are open, the first petals are already falling.
    -   Picture 3: BBCH-stage: 86
        -   Main stage 80: ripening or maturity
        -   Stage 85: Coloring advanced (The color is too light to be ripe but is clearly advanced).

![phenological stages of cherry](https://hortibonn.github.io/Tree-Phenology/pictures/pheno_stages.png) Picture 01: Phenological stages of a cherry tree\

# Chapter 04 Climate change and impact projection

1.  List the main drivers of climate change at the decade to century scale, and briefly explain the mechanism through which the currently most important driver affects our climate.
    -   Main drivers of climate change (influence from decade to century scale)
        -   Greenhouse gases
        -   Aerosols
        -   Clouds
        -   Surface albedo
        -   Ozone
        -   Sun
        -   Long-term drivers
    -   Currently most important for the climate are greenhouse gases and their increasing amount in the atmosphere
        -   The reason are mainly human activities like deforestation, fossil fuel combustion and industrial processes

        -   Greenhouse gases trap heat in the atmosphere

        -   Can absorb only radiation of certain wavelengths

        -   Short-wave radiation from Earth surface is absorbed
2.  Explain briefly what is special about temperature dynamics of recent decades, and why we have good reasons to be concerned.
    -   Recently the mean temperatures are globally rising clearly and very drastically

    -   Especially in the last 50 to 100 years

    -   This an other factors have a great influence in our climate and weather (regional and global)

    -   We will and already do experience more extreme weather (like more dry periods, extreme rain, especially mild and extreme winter)

    -   Most important is the rapid warming (as conclusion)
3.  What does the abbreviation 'RCP' stand for, how are RCPs defined, and what is their role in projecting future climates?
    -   RCP -\> Representative Concentration Pathways

    -   RCPs project future greenhouse gas concentrations (NOT emissions) based on different climate change scenarios until the year 2100

    -   The different scenarios are labeled after the possible radioative forcing values in the year 2100
4.  Briefly describe the 4 climate impact projection methods described in the fourth video.
    -   Statistical models
        -   Analyzes relationships between species occurrences and environmental factors to predict distributions. Often based on historical data.
        -   Does not account for ecological interactions or future adaptability.
    -   Species distribution modeling
        -   Uses species presence/absence data and environmental variables to estimate potential distributions under current and future climates.
        -   Assumes species are in equilibrium with their environment, which may hold under climate change.
    -   Process-based models.
        -   Simulate biological and ecological processes (e.g. metabolism, reproduction) to predict species and ecosystem responses.
        -   Requires extensive species-specific data and is computationally demanding.
    -   Climate analogue analysis
        -   Identifies regions where current conditions resemble projected future climates to predict potential species shifts.

        -   Does not consider non-climatic factors (e.g. land use, human impact) that influence species survival.

# Chapter 05 Winter chill projections

1.  Sketch out three data access and processing challenges that had to be overcome in order to produce chill projections with state-of-the-art methodology.
    -   Climate Data Acquisition
        -   Climate datasets come from multiple sources, such as meteorological stations, reanalysis datasets and climate models.
        -   Differences in spatial and temporal resolution require preprocessing to ensure consistency.
        -   Missing data and measurement errors need handling to avoid distortions in projections.
    -   Model Selection and Calibration
        -   Multiple winter chill models exist (e.g. Chill Hours, Utah Model, Dynamic Model) each responding differently to temperature variations.
        -   Choosing the most appropriate model for a specific region is crucial, as different tree species have varying chill requirements.
        -   Calibration is needed to align models with observed historical data and improve predictive accuracy.
    -   Uncertainty and Bias Correction
        -   Climate models often introduce biases that must be corrected before using their projections.

        -   Different greenhouse gas emission scenarios (e.g. RCP2.6, RCP4.5, RCP8.5) result in a range of possible future conditions, adding uncertainty.

        -   Statistical methods, such as ensemble modeling and probabilistic approaches, help quantify and communicate these uncertainties.
2.  Outline, in your understanding, the basic steps that are necessary to make such projections.
    1.  Data collection and Preprocessing

        -   Gather historical temperature records and future climate projections from global and regional sources.
        -   Standardize the data sets by converting them into compatible formats and resolutions.
        -   Fill in missing data and remove inconsistencies that could affect model accuracy.

    2.  Chill Model Application

        -   Apply a chosen winter chill model to calculate chill accumulation over time.
        -   Compare results from different models to understand their variability and sensitivity.
        -   Validate model outputs against historical observations to ensure reliability.

    3.  Climate Scenario Analysis

        -   Run chill models using projected temperature data under different climate change scenarios.
        -   Analyse how winter chill accumulation might shift in various regions over time.
        -   Compare results across different periods (e.g. near-future vs. late-century) to assess long-term trends.

    4.  Validation and Uncertainty Assessment

        -   Compare modeled projections with historical observations to evaluate accuracy.

        -   Apply statistical techniques to quantify uncertainties and assess model reliability.

        -   Use ensemble approaches to minimize errors and account for variability between models.

    5.  Visualization and Interpretation

        -   Present results using graphs, maps, and reports for easy interpretation.

        -   Provide insights for stakeholders, such as farmers and policymakers, to support decision-making.

        -   Communicate potential risks and adaptation strategies based on projected changes.

```{r child = 'Logbook chapters/treeR_ch6.Rmd'}

```

```{r child = 'Logbook chapters/treeR_ch7.Rmd'}

```

```{r child = 'Logbook chapters/treeR_ch8.Rmd'}

```

```{r child = 'Logbook chapters/treeR_ch9.Rmd'}

```

```{r child = 'Logbook chapters/treeR_ch10.Rmd'}

```

```{r child = 'Logbook chapters/treeR_ch11.Rmd'}

```

```{r child = 'Logbook chapters/treeR_ch12.Rmd'}

```

# Chapter 13 Saving and loading data (and hiding this in markdown)

There are no tasks for this chapter.

```{r child = 'Logbook chapters/treeR_ch14.Rmd'}

```

# Chapter 15 Future temperature scenarios

1.  Briefly describe the differences between the RCPs and the SSPs (you may have to follow some of the links provided above).

The main differences between RCPs (Representative Concentration Pathways) ans SSPs (Shared Socioeconomic Pathways) are the following:

-   Focus

    -   RCPs are defined through greenhouse gas concentrations and radioactive forcing levels

    -   SSPs include socioeconomic factors (e.g. population growth, energy use, policy decisions) along with emissions pathways

-   Drivers of Change

    -   RCPs only consider atmospheric greenhouse gas concentrations and their effects on climate

    -   SSPs include also social, economic and technological factors that influence emissions

-   Policy Relevance

    -   RCPs provide no direct link to human actions or policy decisions

    -   SSPs offer insights into how different societal choices impact climate change

-   Emissions Pathway Representation

    -   RCPs directly define future greenhouse gas concentration levels

    -   SSPs can be paired with radioactive forcing levels for more flexibility

-   RCPs are considered now as outdated and SSPs are now mainly used

```{r child = 'Logbook chapters/treeR_ch16.Rmd'}

```

# Chapter 17 Making CMIP5 scenarios with the ClimateWizard

There are no tasks for this chapter.

```{r child = 'Logbook chapters/treeR_ch18.Rmd'}

```

```{r child = 'Logbook chapters/treeR_ch19.Rmd'}

```


# Chapter 20 Simple phenology analysis

1.  Provide a brief narrative describing what p-hacking is, and why this is a problematic approach to data analysis.

    -   p-hacking

        Is a manipulative approach to data analysis aimed at achieving statistically significant results. Common techniques include selective reporting, cherry-picking variables, or running multiple tests until the p-value falls below 0.05.

    -   Problems

        It increases false positive results which can create misleading conclusions. It also undermines scientific integrity and makes it impossible or very difficult to reproduce results. Additionally, it encourages to only publish "positive" results. All this leads to wasting resources, it can mislead future research and it lowers the public trust in science.

2.  Provide a sketch of your casual understanding of the relationship between temperature and bloom dates.

    Warmer winter and spring temperatures generally lead to earlier bloom dates. Plants require a certain amount of warmth (growing degree days) to sprout in spring. However, they also need a period of cold (chilling requirement) to properly transition into growth.

    Some species need a specific number of cold days in winter before they can respond to warmth. After meeting the chilling requirement, plants need sufficient warmth to trigger blooming. If one requirement isn't met the plant may fail to bloom or show reduced productivity.

3.  What do we need to know to build a process-based model from this?

    -   Key inputs

        -   Temperature data (daily min/max, long-term trends)

        -   Species-specific chilling and heat accumulation thresholds

        -   Day length (photoperiod) for each day

        -   Environmental factors influencing temperature (e.g., topography)

    -   Model Structure

        -   Accumulate chilling degree days from a defined starting point in autumn

        -   After chilling requirements are met, track growing degree days

        -   Link daily min/max temperatures with day length to estimate hourly temperature trends

```{r child = 'Logbook chapters/treeR_ch21.Rmd'}

```

# Chapter 22 Successes and limitations of PLS regression analysis

1.  Briefly explain in what climatic settings we can expect PLS regression to detect the chilling phase - and in what settings this probably wont work.

    PLS would be able to detect the chilling phase in locations with mild winters where warm temperatures reduce the chill accumulation (like in California). In regions with colder winters (like Beijing, China) where a temperature change can increase and decrease chilling it is way more difficult for PLS to detect chilling phases. This is because if it gets too cold the chill accumulation stops and this creates a dynamic that a simple PLS can not detect.

2.  How could we overcome this problem?

    We could create a model that explicitly calculates the chill accumulation instead of an RLS or we apply alternative statistical methods that can capture the nonlinear relationship between chilling and the temperature.

```{r child = 'Logbook chapters/treeR_ch23.Rmd'}

```

# Chapter 24 Examples of PLS regression with agroclimatic metrics

1.  Look across all the PLS results presented above. Can you detect a pattern in where chilling and forcing periods delineated clearly, and where this attempt failed?

    -   Chilling period

        -   In warm climates like in Croatia or Tunisia is the chilling period is clearly visible.

            -   The chilling period is only as long as it needs to be or sometimes even too short what makes it a lot easier to detect the chilling period.

        -   In cold climates like in Beijing or even Klein-Altendorf is the chilling period not easy to detect.

            -   The chilling period is longer than required, what makes it difficult to detect a clear chilling phase

    -   Forcing period

        -   It is easy to detect the forcing period in basically all climates.

        -   This is probably do to the fact that the heat accumulation has a more direct influence on blooming than chilling.

2.  Think about possible reasons for the success or failure of PLS based on agroclimatic metrics. Write down your thoughts.

    -   Reasons for success

        -   Detecting the two phases is easier in climates that have a clearer separation between the chilling and the forcing phase.

        -   If the chilling requirements are just met then the response is clearer to detect.

        -   The forcing period is nearly always good to detect because it has a more direct influence to blooming than chilling.

        -   The choice of Chill model also has an influence on the results, a more simple model like Chilling Hours get less satisfying results than the Dynamic Model.

    -   Reasons for failure

        -   A rather cold climate with a longer chilling period and an overlapping chilling and forcing period is difficult to analyse with a PLS analysis.

        -   PLS analysis assumes linear relationships, which may not capture the complex interactions between chilling, heat, and bloom timing. If only forcing period and blooming are viewed there is a more linear relationship that PLS can detect.

```{r child = 'Logbook chapters/treeR_ch25.Rmd'}

```

```{r child = 'Logbook chapters/treeR_ch26.Rmd'}

```

# Chapter 27The relative importance of chill and heat

1.  Describe the temperature response hypothesis outlined in this chapter.

    The temperature response hypothesis explains how temperature influences tree phenology through chilling and forcing effects. Chilling temperatures are required to release bud dormancy and forcing temperatures to drive bud development and growth. The hypothesis examines how the balance between chilling and forcing temperatures determines the timing of phenological events. Tree species and even single varieties have specific needs in chilling and forcing to produce sufficient fruits.

    In the graphic below is a representation how the relationship of chilling and forcing influences the bloom date of trees.

![Graphical representation of the temperature response hypothesis](https://hortibonn.github.io/Tree-Phenology/pictures/temp_response_hypothesis.jpg){width="508"}

# Chapter 28 Experimentally enhanced PLS

There are no tasks for this chapter.


# Chapter 29

1.  Explain the difference between *output validation* and *process validation*.

-   Output validation

    -   Compares the model's outputs to real-world observations to assess accuracy

    -   The focus is on the end results that the model produces

-   Process validation

    -   Looks into the internal mechanisms and assumptions of the model

    -   The focus is on the model's processes and if they correctly represent real-world systems.

    -   So rather than validating only the model's results it checks if the path to get the results aligns with reality

2.  Explain what a *validity domain* is and why it is important to consider this whenever we want to use our model to forecast something.

-   Validity domain

    Defines the boundaries within which the model works in a useful way and delivers reliable results.

-   Importance

    Ensures that the model is applied only to situations where it has been validated and prevents misuse.

3.  What is *validation for purpose*?

    Assesses if a model is suitable for a specific intended application. It checks if the model meets the requirements and objectives of the intended use. Also the accuracy of the model and its relevance to the specific context are evaluated.

4.  How can we ensure that our model is suitable for the predictions we want to make?

    To ensure this there are some steps that need to be followed:

    1.  Define the models purpose and clearly outline the specific objectives and applications of the desired model.

    2.  Validate your chosen model. For this use both output and process validation to assess accuracy and internal consistency.

    3.  Determine the model's valid range. Identify the conditions under which the model operates reliably.

    4.  Do continuous evaluations of the model to ensure its accuracy. Compare the model's predictions to real-world data and update the model if errors occur.

# Chapter 30 The PhenoFlex Model

1.  Parameterize the PhenoFlex model for \`Roter Boskoop’ apples.

```{r, echo = FALSE, results = 'hide', message = FALSE, warning = FALSE}
rm(list=ls())

library(chillR)
library(leaflet)
library(tidyverse)
library(kableExtra)
library(Kendall)
library(patchwork)
```

```{r}
Boskoop <-
  read_tab("D:/! Ricardas Daten/Studium/Master/03. Semester (WiSe 24-25)/Tree phenology analysis in R/Logbook chapters/Roter_Boskoop_bloom_1958_2019.csv") %>%
  select(Pheno_year, First_bloom) %>%
  mutate(Year = as.numeric(substr(First_bloom, 1, 4)),
         Month = as.numeric(substr(First_bloom, 5, 6)),
         Day = as.numeric(substr(First_bloom, 7, 8))) %>%
  make_JDay() %>%
  select(Pheno_year, JDay) %>%
  rename(Year = Pheno_year,
         pheno = JDay)

hourtemps <- 
  read_tab("D:/! Ricardas Daten/Studium/Master/03. Semester (WiSe 24-25)/Tree phenology analysis in R/Logbook chapters/TMaxTMin1958-2019_patched.csv") %>%
  stack_hourly_temps(latitude = 50.6)

par <-   c(40, 190, 0.5, 25, 3372.8,  9900.3, 6319.5, 5.939917e13,  4, 36,  4,  1.60)
upper <- c(41, 200, 1.0, 30, 4000.0, 10000.0, 7000.0, 6.e13, 10, 40, 10, 50.00)
lower <- c(38, 180, 0.1, 0 , 3000.0,  9000.0, 6000.0, 5.e13,  0,  0,  0,  0.05)

SeasonList <- genSeasonList(hourtemps$hourtemps,
                            mrange = c(8, 6),
                            years = c(1959:2019))
```

```{r, eval = FALSE}
Fit_res <- phenologyFitter(par.guess = par, 
                           modelfn = PhenoFlex_GDHwrapper,
                           bloomJDays = Boskoop$pheno[which(Boskoop$Year > 1957)],
                           SeasonList = SeasonList,
                           lower = lower,
                           upper = upper,
                           control = list(smooth = FALSE,
                                          verbose = FALSE, 
                                          maxit = 1000,
                                          nb.stop.improvement = 5))

Boskoop_par <- Fit_res$par

write.csv(Boskoop_par, "D:/! Ricardas Daten/Studium/Master/03. Semester (WiSe 24-25)/Tree phenology analysis in R/Logbook chapters/PhenoFlex_parameters_roter_Boskoop.csv")
```



2.  Produce plots of predicted vs. observed bloom dates and distribution of prediction errors.

```{r}
Boskoop_par <- read_tab("D:/! Ricardas Daten/Studium/Master/03. Semester (WiSe 24-25)/Tree phenology analysis in R/Logbook chapters/PhenoFlex_parameters_roter_Boskoop.csv")[,2]

SeasonList <- genSeasonList(hourtemps$hourtemps, 
                            mrange = c(8, 6),
                            years = c(1959:2019))

Boskoop_PhenoFlex_predictions <- Boskoop[which(Boskoop$Year > 1958),]

for(y in 1:length(Boskoop_PhenoFlex_predictions$Year))
   Boskoop_PhenoFlex_predictions$predicted[y] <-
    PhenoFlex_GDHwrapper(SeasonList[[y]],
                         Boskoop_par)

Boskoop_PhenoFlex_predictions$Error <- 
  Boskoop_PhenoFlex_predictions$predicted - 
  Boskoop_PhenoFlex_predictions$pheno

ggplot(Boskoop_PhenoFlex_predictions,
       aes(x = pheno,
           y = predicted)) +
  geom_point() +
  geom_abline(intercept = 0,
              slope = 1) +
  theme_bw(base_size = 15) +
  xlab("Observed bloom date (Day of the year)") +
  ylab("Predicted bloom date (Day of the year)") +
  ggtitle("Predicted vs. observed bloom dates")

ggplot(Boskoop_PhenoFlex_predictions,
       aes(Error)) +
  geom_histogram() +
  ggtitle("Distribution of prediction errors")
```

3.  Compute the model performance metrics RMSEP, mean error and mean absolute error.

```{r}
RMSEP(Boskoop_PhenoFlex_predictions$predicted,
      Boskoop_PhenoFlex_predictions$pheno)

mean(Boskoop_PhenoFlex_predictions$Error)

mean(abs(Boskoop_PhenoFlex_predictions$Error))
```

# Chapter 31 The PhenoFlex Model - a second look

1.  Make chill and heat response plots for the ‘Roter Boskoop’ PhenoFlex model for the location you did the earlier analyses for.

I really tried to incorporate my own temperature data, but I wasn't able to fin out how to fix the code to the shorter time span (1990-2019 instead of 1958-2019). Even if I got the bloomJDays andSeasonList to the same length I still got error messages that there are some statements not fully met. So Iswitched back to the CKA temperatures to be able to create the plots correctly.

```{r, eval = FALSE}
Boskoop <- read_tab("D:/! Ricardas Daten/Studium/Master/03. Semester (WiSe 24-25)/Tree phenology analysis in R/Logbook chapters/Roter_Boskoop_bloom_1958_2019.csv") %>%
  select(Pheno_year, First_bloom) %>%
  mutate(Year = as.numeric(substr(First_bloom, 1, 4)),
         Month = as.numeric(substr(First_bloom, 5, 6)),
         Day = as.numeric(substr(First_bloom, 7, 8))) %>%
  make_JDay() %>%
  select(Pheno_year, JDay) %>%
  rename(Year = Pheno_year,
         pheno = JDay)

temp_data <- read.csv("D:/! Ricardas Daten/Studium/Master/03. Semester (WiSe 24-25)/Tree phenology analysis in R/Logbook chapters/TMaxTMin1958-2019_patched.csv") %>% stack_hourly_temps(latitude = 50.6)

par <-   c(40, 190, 0.5, 25, 3372.8,  9900.3, 6319.5, 5.939917e13,  4, 36,  4,  1.60)
upper <- c(41, 200, 1.0, 30, 4000.0, 10000.0, 7000.0, 6.e13, 10, 40, 10, 50.00)
lower <- c(38, 180, 0.1, 0 , 3000.0,  9000.0, 6000.0, 5.e13,  0,  0,  0,  0.05)

SeasonList <- genSeasonList(temp_data$temp_data,
                            mrange = c(8, 6),
                            years = c(1959:2019))

Fit_res <- phenologyFitter(par.guess = par, 
                           modelfn = PhenoFlex_GDHwrapper,
                           bloomJDays = Boskoop$pheno[which(Boskoop$Year > 1957)],
                           SeasonList = SeasonList,
                           lower = lower,
                           upper = upper,
                           control = list(smooth = FALSE,
                                          verbose = FALSE, 
                                          maxit = 1000,
                                          nb.stop.improvement = 5))

Boskoop_par <- Fit_res$par

write.csv(Boskoop_par, "D:/! Ricardas Daten/Studium/Master/03. Semester (WiSe 24-25)/Tree phenology analysis in R/Logbook chapters/PhenoFlex_parameters_roter_Boskoop.csv")
```


```{r}
apply_const_temp <-
  function(temp, A0, A1, E0, E1, Tf, slope, portions = 1200, deg_celsius = TRUE)
    {
  temp_vector <- rep(temp,
                     times = portions)
  res <- chillR::DynModel_driver(temp = temp_vector,
                                 A0 = A0,
                                 A1 = A1,
                                 E0 = E0,
                                 E1 = E1,
                                 Tf = Tf,
                                 slope = slope,
                                 deg_celsius = deg_celsius)
  return(res$y[length(res$y)])
}

gen_bell <- function(par,
                     temp_values = seq(-5, 20, 0.1)) {
  E0 <- par[5]
  E1 <- par[6]
  A0 <- par[7]
  A1 <- par[8]
  Tf <- par[9]
  slope <- par[12]

  y <- c()
  for(i in seq_along(temp_values)) {
    y[i] <- apply_const_temp(temp = temp_values[i],
                             A0 = A0,
                             A1 = A1,
                             E0 = E0,
                             E1 = E1,
                             Tf = Tf,
                             slope = slope)
  }
  return(invisible(y))
}

GDH_response <- function(T, par)
  {Tb <- par[11]
   Tu <- par[4]
   Tc <- par[10]
   GDH_weight <- rep(0, length(T))
   GDH_weight[which(T >= Tb & T <= Tu)] <-
     1/2 * (1 + cos(pi + pi * (T[which(T >= Tb & T <= Tu)] - Tb)/(Tu - Tb)))
   GDH_weight[which(T > Tu & T <= Tc)] <-
     (1 + cos(pi/2 + pi/2 * (T[which(T >  Tu & T <= Tc)] -Tu)/(Tc - Tu)))
  return(GDH_weight)
}
```

```{r}
Boskoop <- read_tab("D:/! Ricardas Daten/Studium/Master/03. Semester (WiSe 24-25)/Tree phenology analysis in R/Logbook chapters/PhenoFlex_parameters_roter_Boskoop.csv")[,2]

temp_values = seq(-5, 30, 0.1)

temp_response <- data.frame(Temperature = temp_values,
                            Chill_response = gen_bell(Boskoop,
                                                      temp_values),
                            Heat_response = GDH_response(temp_values,
                                                         Boskoop))

pivoted_response <- pivot_longer(temp_response, 
                                 c(Chill_response,
                                   Heat_response))

ggplot(pivoted_response,
       aes(x = Temperature,
           y = value)) +
  geom_line(linewidth = 2,
            aes(col = name)) +
  ylab("Temperature response (arbitrary units)") +
  xlab("Temperature (°C)") +
  facet_wrap(vars(name),
             scales = "free",
             labeller = 
               labeller(name = c(Chill_response = c("Chill response"),
                                     Heat_response = c("Heat response")))) +
  scale_color_manual(values = c("Chill_response" = "blue",
                                "Heat_response" = "red")) +
  theme_bw(base_size = 15) +
  theme(legend.position = "none")
```


# Chapter 32 Can we improve the performance of PhenoFlex?

1.  What was the objective of this work?

    The study aimed to enhance the performance of the PhenoFlex model by refining its calibration process.

2.  What was the main conclusion?

    That the PhenoFlex model's performance improved when using a calibration approach that incorporated the standard deviation and the mean absolute error of phenological dates.

3.  What experiments could we conduct to test the hypothesis that emerged at the end of the conclusion?

    -   Cross-validation

        -   Apply the model to diverse datasets (different geographic regions and spiecies) to test the robustness and generalizability of the PhenoFlex Model.

        -   Use the new data to test the calibrations that were done with the already present data.

    -   Comparative analysis

        -   Compare the predictive accuracy of the PhenoFlex model calibrated with the combined approach against models calibrated with only one of the error metrics to evaluate the performance differences.

    -   Sensitivity analysis

        -   Investigate how variations in weighting between standard deviation and mean absolute error during calibration affect the model's predictions to determine optimal calibration settings.

    -   Longitudinal studies

        -   Monitor the model's predictive performance over multiple years to ensure that the improved calibration method maintains its accuracy over time.

# Chapter 33 Frost risk analysis

1.  Illustrate the development of the bloom period over the duration of the weather record. Use multiple ways to show this - feel free to be creative.

```{r}
CKA_Boskoop <- read_tab("D:/! Ricardas Daten/Studium/Master/03. Semester (WiSe 24-25)/Tree phenology analysis in R/Logbook chapters/Roter_Boskoop_bloom_1958_2019.csv")

CKA_weather <- read_tab("D:/! Ricardas Daten/Studium/Master/03. Semester (WiSe 24-25)/Tree phenology analysis in R/Logbook chapters/TMaxTMin1958-2019_patched.csv")

CKA_Boskoop <- 
  CKA_Boskoop %>%
  pivot_longer(cols = "First_bloom":"Last_bloom",
               names_to = "variable",
               values_to="YEARMODA") %>%
  mutate(Year = as.numeric(substr(YEARMODA, 1, 4)),
         Month = as.numeric(substr(YEARMODA, 5, 6)),
         Day = as.numeric(substr(YEARMODA, 7, 8))) %>%
  make_JDay() 
```

```{r}
ggplot(data = CKA_Boskoop,
       aes(Pheno_year,
           JDay,
           col = variable)) +
  geom_line() +
  theme_bw(base_size = 15) +
  scale_color_discrete(
    name = "Phenological event",
    labels = c("First bloom",
               "Full bloom",
               "Last bloom")) +
  xlab("Phenological year") +
  ylab("Julian date (day of the year)")

ggplot(data = CKA_Boskoop,
       aes(Pheno_year,
           JDay,
           col = variable)) +
  geom_line() +
  theme_bw(base_size = 15) +
  scale_color_discrete(name = "Phenological event",
                       labels = c("First bloom",
                                  "Full bloom", 
                                  "Last bloom")) +
  xlab("Phenological year") +
  ylab("Julian date (day of the year)") +
  geom_smooth(method = "lm")

ggplot(data=CKA_Boskoop,aes(Pheno_year,JDay,col=variable)) +
  geom_smooth() +
  theme_bw(base_size=15) +
  scale_color_discrete(
    name = "Phenological event",
    labels = c("First bloom", "Full bloom", "Last bloom")) +
  xlab("Phenological year") +
  ylab("Julian date (day of the year)") 
```

2.  Evaluate the occurrence of frost events at Klein-Altendorf since 1958. Illustrate this in a plot.

```{r}
require(Kendall)
Kendall_first <-
  Kendall(x = CKA_Boskoop$Pheno_year[
            which(CKA_Boskoop$variable == "First_bloom")],
          y = CKA_Boskoop$JDay[
            which(CKA_Boskoop$variable == "First_bloom")])

Kendall_full <- 
  Kendall(x = CKA_Boskoop$Pheno_year[
            which(CKA_Boskoop$variable == "Full_bloom")],
          y = CKA_Boskoop$JDay[
            which(CKA_Boskoop$variable == "Full_bloom")])

Kendall_last <- 
  Kendall(x = CKA_Boskoop$Pheno_year[
            which(CKA_Boskoop$variable == "Last_bloom")],
          y = CKA_Boskoop$JDay[
            which(CKA_Boskoop$variable == "Last_bloom")])

Kendall_first

Kendall_full

Kendall_last
```
The p-values are all smaller than 0.05, so it is pretty clear that there is a trend.

```{r}
frost_df = data.frame(
  lower = c(-1000, 0),
  upper = c(0, 1000),
  weight = c(1, 0))

frost_model <- function(x) step_model(x,
                                      frost_df)

hourly <- stack_hourly_temps(CKA_weather,
                             latitude = 50.625)

frost <- tempResponse(hourly,
                      models = c(frost = frost_model))

ggplot(frost,
       aes(End_year,
           frost)) +
  geom_smooth() +
  geom_point() +
  ylim(c(0, NA)) +
  ylab("Frost hours per year") +
  xlab("Year")
```



3.  Produce an illustration of the relationship between spring frost events and the bloom period of ‘Roter Boskoop’.

```{r, warning = FALSE}
frost_model_no_summ <- 
  function(x) step_model(x, 
                         frost_df,
                         summ=FALSE)

hourly$hourtemps[, "frost"] <- frost_model_no_summ(hourly$hourtemps$Temp)

Daily_frost_hours <- aggregate(hourly$hourtemps$frost,
                               by = list(hourly$hourtemps$YEARMODA),
                               FUN = sum)

Daily_frost <- make_JDay(CKA_weather)

Daily_frost[, "Frost_hours"] <- Daily_frost_hours$x

Daily_frost$Frost_hours[which(Daily_frost$Frost_hours == 0)] <- NA

Ribbon_Boskoop <-
  CKA_Boskoop %>%
  select(Pheno_year, variable, JDay) %>%
  pivot_wider(names_from = "variable", values_from = "JDay")

lookup_dates <- Ribbon_Boskoop

row.names(lookup_dates) <- lookup_dates$Pheno_year

Daily_frost[, "First_bloom"]<-
  lookup_dates[as.character(Daily_frost$Year),
               "First_bloom"]

Daily_frost[, "Last_bloom"]<-
  lookup_dates[as.character(Daily_frost$Year),
               "Last_bloom"]

Daily_frost[which(!is.na(Daily_frost$Frost_hours)),
            "Bloom_frost"] <-
  "Before bloom"

Daily_frost[which(Daily_frost$JDay >= Daily_frost$First_bloom),
            "Bloom_frost"]<-
  "During bloom"

Daily_frost[which(Daily_frost$JDay > Daily_frost$Last_bloom),
            "Bloom_frost"]<-
  "After bloom"

Daily_frost[which(Daily_frost$JDay > 180),
            "Bloom_frost"]<-
  "Before bloom"

ggplot(data = Ribbon_Boskoop,
       aes(Pheno_year)) +
  geom_ribbon(aes(ymin = First_bloom, 
                  ymax = Last_bloom),
              fill = "light gray") +
  geom_line(aes(y = Full_bloom)) +
  theme_bw(base_size = 15) +
  xlab("Phenological year") +
  ylab("Julian date (day of the year)") +
  geom_point(data = Daily_frost,
             aes(Year,
                 JDay,
                 size = Frost_hours,
                 col = Bloom_frost),
             alpha = 0.8) + 
  scale_size(range = c(0, 5),
             breaks = c(1, 5, 10, 15, 20),
             labels = c("1", "5", "10", "15", "20"),
             name = "Frost hours") +
  scale_color_manual(
    breaks = c("Before bloom",
               "During bloom",
               "After bloom"),
    values = c("light green",
               "red",
               "light blue"),
    name = "Frost timing") +
  theme_bw(base_size = 15) +
  ylim(c(75, 140))
```

4.  Evaluate how the risk of spring frost for this cultivar has changed over time. Has there been a significant trend?

    In the viewed period is a trend visible that shows earlier bloom dates, which could increase the risk of frost damage. However, there is no higher greater frost damage risk visible in the data.

# Chapter 34 A robust method to estimate future frost risks (?)

There are no tasks for this chapter.

# Chapter 35 Major concepts

There are no tasks for this chapter.






